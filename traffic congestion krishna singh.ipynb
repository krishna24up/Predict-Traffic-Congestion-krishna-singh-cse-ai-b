{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJT1PVN9sIeu"
      },
      "outputs": [],
      "source": [
        "# Step 1: Upload File\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Import Libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#  Step 3: Load CSV\n",
        "data = pd.read_csv('traffic_congestion.csv')\n",
        "\n",
        "#  Step 4: Clean Column Names\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "#  Step 5: Show Columns\n",
        "print(\"Columns in dataset:\")\n",
        "print(data.columns)\n",
        "\n",
        "# Step 6: Detect Target Column\n",
        "target_column = None\n",
        "for col in data.columns:\n",
        "    if \"congestion\" in col.lower() and \"level\" in col.lower():\n",
        "        target_column = col\n",
        "        break\n",
        "\n",
        "if not target_column:\n",
        "    raise Exception(\"Target column for congestion not found. Please verify your file.\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Target Column: {target_column}\")\n",
        "\n",
        "#  Step 7: Handle Missing Values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "#  Step 8: Encode All Categorical Columns (except target)\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in data.columns:\n",
        "    if data[col].dtype == 'object' and col != target_column:\n",
        "        data[col] = label_encoder.fit_transform(data[col])\n",
        "\n",
        "#  Step 9: Encode Target (if needed)\n",
        "if data[target_column].dtype == 'object':\n",
        "    data[target_column] = label_encoder.fit_transform(data[target_column])\n",
        "\n",
        "#  Step 10: Features and Target Split\n",
        "X = data.drop(target_column, axis=1)\n",
        "y = data[target_column]\n",
        "\n",
        "#  Step 11: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#  Step 12: Train Model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#  Step 13: Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#  Step 14: Evaluation\n",
        "print(\"\\nðŸ“ˆ Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#  Step 15: Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - Traffic Congestion\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "#  Step 16: Feature Importance\n",
        "importances = model.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=importances, y=features)\n",
        "plt.title(\"Feature Importance for Congestion Prediction\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-XFkfDBuK1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}